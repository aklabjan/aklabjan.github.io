<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="Herb Leaf Classification System" content="CS766 Project" />
    <meta name="Ana Klabjan, Poulami Paul and Shubhankit Rathore" content="CS766 Project" />
    <title>CS766 Project</title>
    <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
    <!-- Google fonts-->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet"
        type="text/css" />
    <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="css/styles.css" rel="stylesheet" />
</head>

<body id="page-top">
    <!-- Navigation-->
    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">
            <span class="d-block d-lg-none">Herb Leaf Classification System</span>
            <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2"
                    src="assets/img/tomatoes.jpeg" alt="..." /></span>
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive"
            aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span
                class="navbar-toggler-icon"></span></button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Title">Project Details</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#TheProblem">The Problem</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#StateOfTheArt">Current State Of The
                        Art</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Approach">Our Approach</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Implementation">Implementation
                        Overview</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Stages">Indepth Walk Through</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Discussion">Discussion</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Resources">Resources</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#References">References</a></li>
            </ul>
        </div>
    </nav>
    <!-- Page Content-->
    <div class="container-fluid p-0">
        <!-- Title and Names-->
        <section class="resume-section" id="Title">
            <div class="resume-section-content">
                <h2 class="mb-0"><span class="text-primary">Herb Leaf </span>Classification System</h2>
                <p class="lead mb-5">
                    By Ana Klabjan, Poulami Paul and Shubhankit Rathore
                </p>
                <p class="lead mb-5">CS 766-Spring 2023</p>
            </div>
        </section>
        <hr class="m-0" />
        <!-- TheProblem-->
        <section class="resume-section" id="TheProblem">
            <div class="resume-section-content">
                <h2 class="mb-0">
                    The
                    <span class="text-primary">Problem</span>
                </h2>
                <p class="lead mb-5"> The problem we are trying to solve is to accurately label different herbs in a
                    herb garden when a photo is taken. Specifically, we aim to identify the herbs parsley, thyme,
                    chives, and oregano, while labeling all other herbs as unclassified herb. The goal of this project
                    is to develop a computer vision model that can recognize these specific herbs in an image with high
                    accuracy and efficiency.
                    <br><br>
                    It might be out of curiosity for someone to figure out what kind of herbs they have in their garden
                    or forest. Accurate classification of herb leaves is critical for quality control, authentication,
                    and conservation of medicinal plants. Therefore, the proposed project aims to develop a herb leaf
                    classification system that can identify individual plants within a garden and differentiate between
                    different herb species based on their leaf images.
                </p>
                <h3 class="mb-0">
                    Importance and Motivation
                </h3>
                <p class="lead mb-5">The problem we are trying to solve is important for several reasons. Firstly, it
                    can satisfy the curiosity of people who want to know what kind of herbs they have in their garden or
                    environment. This can be time-consuming and challenging for those without extensive herb knowledge.
                    Secondly, this tool can also be helpful for the food industry, as it can assist with quality control
                    in the production of herb-infused products and reduce the risk of misidentification, which can be
                    dangerous if a misidentified herb is consumed.
                    <br><br>
                    Lastly, accurate identification of herb leaves is crucial for quality control, authentication, and
                    conservation of medicinal plants. The development of a herb leaf classification system that can
                    identify different herb species based on their leaf images can aid in the production of medicines,
                    as well as the identification and preservation of endangered plant species. Additionally, the
                    accurate labeling of herbs in natural environments can provide valuable data for ecological studies,
                    aiding in the conservation and management of natural habitats. Therefore, it is crucial to develop a
                    computer vision model that can accurately and efficiently identify different herb species in images,
                    as it has practical applications for the food industry, herb enthusiasts, medicinal purposes, and
                    environmental research.
                    <br><br>
            </div>
        </section>
        <hr class="m-0" />
        <!-- StateOfTheArt-->
        <section class="resume-section" id="StateOfTheArt">
            <div class="resume-section-content">
                <h2 class="mb-0">Current State Of The Art</h2>
                <p class="lead mb-5">In recent years, herb classification using leaf images has gained significant
                    attention due to its potential applications in the fields of medicine, agriculture, and food
                    industry. The ability to accurately identify different herb species can help in quality control of
                    herbal products, detection of adulteration, and conservation of rare and endangered plant species.
                    <br><br>
                    Most of the existing studies in this area have focused on the extraction of features from images
                    that represent a singular leaf from an herb and their classification using various machine learning
                    algorithms. Texture features, color histograms, and shape descriptors are some of the commonly used
                    features for herb classification[3]. However, with the recent advancements in deep
                    learning, several studies have started exploring the use of convolution neural networks (CNNs) for
                    herb recognition based on leaf images[1].
                    Leaf identification normally use images that taken in the laboratory with sophisticated equipment
                    and a white background. The accuracy of these models have been high.
                    <br><br>
                    Current research has shifted the focus from high-quality plant images to identifying leaves in
                    natural environments. Leaf segmentation in natural environments has different approaches and
                    accuracy levels. There have been many studies that aim to identify leaves based on images taken in
                    their natural environment[2]. These studies all focused on the identification of a
                    singular leaf taken in nature. The accuracy of the models was lower than the models discussed in the
                    prior paragraph that used images taken with sophisticated equipment and a white background, but the
                    models were still considered successful, with high accuracy.
                </p>
            </div>
        </section>
        <hr class="m-0" />
        <!-- Method-->
        <section class="resume-section" id="Approach">
            <div class="resume-section-content">
                <h2 class="mb-0">Our Approach</h2>
                <p class="lead mb-5">Our project intends to expand on the current state-of-the-art. The research for
                    identifying an individual leaf from nature has already been conducted, and our project expands on
                    it. However, we have not found any studies that take an image of numerous plants and segment the
                    image to locate each individual plant. Each segmented plant would then be fed into an identification
                    model, similar to the pre-existing ones.
                    <br><br>
                    For plant segmentation, we have developed our own approach. Firstly, we will identify the center of
                    each individual plant and annotate it on the original image. To do this, we will convert the herb
                    garden image to grayscale, compute the edges/boundaries, perform some noise removal, and then
                    identify each individual plant and the coordinates of its center.
                    <br><br>
                    We plan to use the center coordinates of each plant to segment the image into sub-images that will
                    then be fed into our identification model. Currently, the approach we plan to use to extract the
                    sub-images is to take the plant center, create a box around it, and extract the pixels in the
                    surrounding box as a new image. Finally, these segmented image for identified plants would be sent
                    to the classification model to predict the type of plant. Each image will then be labelled as one of
                    the possible plants as discussed previously, or unidentifiable herb if the confidence score for the
                    prediction is lower than a pre-determined threshold.
                </p>

                <h3 class="mb-0">Dataset</h3>
                <p class="lead mb-5">For this project, we were unable to find an already existing dataset. Therefore, we
                    will be creating our own dataset for the training & testing of model from Google Images. To create
                    the training & testing set we will pull 500-1000 images from Google Images for each of our four
                    herb types: parsley, thyme, chives, and oregano, and split the set into 90% and 10% to train &
                    test.
                    <br><br>
                    For the final test set we will be pulling 20-30 images of herb gardens. We will manually label these
                    images to test the prediction of our trained model in presence of multiple herbs in a single image.
                    Our main goal is to segment these herb garden images to segment into different herb-leaves region
                    and then predict their type in the image and label them.
                </p>
            </div>
        </section>
        <hr class="m-0" />
        <!-- Implementation-->
        <section class="resume-section" id="Implementation">
            <div class="resume-section-content">
                <h2 class="mb-0">Implementation Overview</h2>
                <p class="lead mb-5">
                    We programmed a script that extracted 240 images from google for each of the four classes, parsley,
                    thyme, chives,
                    and oregano. The images were preprocessed to 224 by 224 and split into train/test sets. The train
                    set was then used to train a <i>MobileNet</i> model with a custom output layer. The model has a
                    ~95% accuracy on the test set.
                    <br><br>
                    The caveat with this approach is that we have not manually inspected the dataset of images,
                    therefore our model may have some misrepresented images. For example, when looking at the labeled
                    images for parsley you will find some that are an image of prepackages dried parsley including the
                    text "Parsley". We believe this error in our dataset might be causing our model to overfit,
                    potentially affecting negatively on the ability to correctly identify the plant after segmentation
                    in the future. This is something we will have to revisit once we start feeding the segmented image
                    into the model.
                    <br><br>
                    22 images were then extracted from Instagram to use as the test set for the image segmentation.
                    Instagram was used as it was a reliable method to get test images that best resemble being taken
                    from a natural environment with a normal phone camera. For labeling purposes we choose images that
                    included the gardener labeling the plants, this eliminated the need for the three of us, who are not
                    herb experts from misidentifying the plants. This once again leads to the caveat that we don't want
                    the herb names in our test images as we believe it has potential for our model to incorrectly learn
                    the name of the plants instead of the leafs identifying feature. The major goal of our project is to
                    take an herb garden where you don't know what is what and label it, therefore in the pre-processing
                    of the test images we blurred out any identifying labels of the herbs in the image. Any text/labels
                    were removed from images using Keras_ocr and cv2 API. The removal of text will be referred as Stage
                    1.
                    <br><br>
                    The image is then converted to black and white then processed with regionprop.
                    annotated with the center of
                    each herb using . This feature implementation is currently in
                    progress, broken down into several stages. Stage two
                    has been completed, converting the images to black and
                    white, the connected components are labeled and lastly
                    the center of each component is computed. When anno-
                    tating these centers on the images we find that there tends
                    to be clusters of ”centers” around each plant
                <div>Stage 2 Output:
                    <img src="./assets/img/annotate.png" alt="Example image of stage two output." width="500">
                </div>
                <br><br>
                This leads to stage 3 which is currently under execution. Stage-3 will encompass the major task of
                locating the approximate true center of each plant using the points found in stage-2. A filter needs to
                be applied for the removal of outlier points in the image and then we will tentatively use k-means for
                locating the true center for each of the cluster of points which represents a plant.
                </p>
            </div>
        </section>
        <hr class="m-0" />
        <!-- Stages-->
        <section class="resume-section" id="Stages">
            <div class="resume-section-content">
                <h2 class="mb-0">Indepth Walk Through</h2>
                <p class="lead mb-5">
                    TO DO
                </p>

                <div>Stage 2 Output:
                    <img src="./assets/img/annotate.png" alt="Example image of stage two output.">
                </div>

                <div>Image 2.
                    <img src="./assets/img/misclass_2.png" alt="Misclassification 2">
                </div>

                <div>Image 3.
                    <img src="./assets/img/misclass_3.png" alt="Misclassification 3">
                </div>

                <img src="./assets/img/conf_mat.png" alt="Confusion Matrix">
                <div>Figure 1. Confusion matrix between the three classes in the test data set.</div>


            </div>
        </section>
        <hr class="m-0" />
        <!-- Discussion-->
        <section class="resume-section" id="Discussion">
            <div class="resume-section-content">
                <h2 class="mb-0">Discussion</h2>
                <h3 class="mb-0">Challenges & Lessons</h3>
                <p class="lead mb-5">
                    TO DO
                </p>
                <p class="lead mb-5">
                    TO DO
                </p>
            </div>
        </section>
        <hr class="m-0" />
        <!-- Resources-->
        <section class="resume-section" id="Resources">
            <div class="resume-section-content">
                <h2 class="mb-0">Resources</h2>
                <ul class="lead mb-5">
                    <li>
                        <a href="https://github.com/aklabjan/herbDetectionProject">Github Repository</a>
                    </li>
                    <li>
                        <a
                            href="https://docs.google.com/presentation/d/15zjstpBCiju-LM5Yy18rcPJ7A-Ig731SxNGlmBvt9vg/edit?usp=sharing">Presentation</a>
                    </li>
                </ul>
            </div>
        </section>
        <!-- References-->
        <section class="resume-section" id="References">
            <div class="resume-section-content">
                <h2 class="mb-0">References</h2>
                <ol class="lead mb-5">
                    <li>
                        <div id="ref-8687165" class="csl-entry" role="doc-biblioentry">
                            Liu, Shupeng, Weiyang Chen, and Xiangjun Dong. 2018. <span>“Automatic
                                Classification of Chinese Herbal Based on Deep Learning Method.”</span>
                            In <em>2018 14th International Conference on Natural Computation, Fuzzy
                                Systems and Knowledge Discovery (ICNC-FSKD)</em>, 235–38. <a
                                href="https://doi.org/10.1109/FSKD.2018.8687165">https://doi.org/10.1109/FSKD.2018.8687165</a>.
                        </div>
                    </li>
                    <li>
                        <div id="ref-8350775" class="csl-entry" role="doc-biblioentry">
                            Mareta, Affix, Indah Soesanti, and Oyas Wahyunggoro. 2018. <span>“Herbal
                                Leaf Classification Using Images in Natural Background.”</span> In
                            <em>2018 International Conference on Information and Communications
                                Technology (ICOIACT)</em>, 612–16. <a
                                href="https://doi.org/10.1109/ICOIACT.2018.8350775">https://doi.org/10.1109/ICOIACT.2018.8350775</a>.
                        </div>
                    </li>
                    <li>
                        <div id="ref-9239938" class="csl-entry" role="doc-biblioentry">
                            Muneer, Amgad, and Suliman Mohamed Fati. 2020. <span>“Efficient and
                                Automated Herbs Classification Approach Based on Shape and Texture
                                Features Using Deep Learning.”</span> <em>IEEE Access</em> 8: 196747–64.
                            <a
                                href="https://doi.org/10.1109/ACCESS.2020.3034033">https://doi.org/10.1109/ACCESS.2020.3034033</a>.
                        </div>
                    </li>
                </ol>
            </div>
        </section>
        <hr class="m-0" />
    </div>
    <!-- Bootstrap core JS-->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Core theme JS-->
    <script src="js/scripts.js"></script>
</body>

</html>