<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="Herb Leaf Classification System" content="CS766 Project" />
    <meta name="Ana Klabjan, Poulami Paul and Shubhankit Rathore" content="CS766 Project" />
    <title>CS766 Project</title>
    <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
    <!-- Google fonts-->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet"
        type="text/css" />
    <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="css/styles.css" rel="stylesheet" />
</head>

<body id="page-top">
    <!-- Navigation-->
    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">
            <span class="d-block d-lg-none">Herb Leaf Classification System</span>
            <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2"
                    src="assets/img/tomatoes.jpeg" alt="..." /></span>
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive"
            aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span
                class="navbar-toggler-icon"></span></button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Title">Project Details</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#TheProblem">The Problem</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#StateOfTheArt">Current State Of The
                        Art</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Method">Method</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Implementation">Implementation
                        Details</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Results">Results</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Discussion">Discussion</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Resources">Resources</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#References">References</a></li>
            </ul>
        </div>
    </nav>
    <!-- Page Content-->
    <div class="container-fluid p-0">
        <!-- Title and Names-->
        <section class="resume-section" id="Title">
            <div class="resume-section-content">
                <h2 class="mb-0"><span class="text-primary">Herb</span> Leaf Classification System</h2>
                <p class="lead mb-5">
                    By Ana Klabjan, Poulami Paul and Shubhankit Rathore
                </p>
                <p class="lead mb-5">CS 766-Spring 2023</p>
            </div>
        </section>
        <hr class="m-0" />
        <!-- TheProblem-->
        <section class="resume-section" id="TheProblem">
            <div class="resume-section-content">
                <h2 class="mb-0">
                    The
                    <span class="text-primary">Problem</span>
                </h2>
                <p class="lead mb-5"> The problem we are trying to solve is to accurately label different herbs in a
                    herb garden when a photo is taken. Specifically, we aim to identify the herbs parsley, thyme,
                    chives, and oregano, while labeling all other herbs as unclassified herb. The goal of this project
                    is to develop a computer vision model that can recognize these specific herbs in an image with high
                    accuracy and efficiency.
                    <br><br>
                    It might be out of curiosity for someone to figure out what kind of herbs they have in their garden
                    or forest. Accurate classification of herb leaves is critical for quality control, authentication,
                    and conservation of medicinal plants. Therefore, the proposed project aims to develop a herb leaf
                    classification system that can identify individual plants within a garden and differentiate between
                    different herb species based on their leaf images.
                </p>
                <h3 class="mb-0">
                    Importance and Motivation
                </h3>
                <p class="lead mb-5">The problem we are trying to solve is important for several reasons. Firstly, it
                    can satisfy the curiosity of people who want to know what kind of herbs they have in their garden or
                    environment. This can be time-consuming and challenging for those without extensive herb knowledge.
                    Secondly, this tool can also be helpful for the food industry, as it can assist with quality control
                    in the production of herb-infused products and reduce the risk of misidentification, which can be
                    dangerous if a misidentified herb is consumed.
                    <br><br>
                    Lastly, accurate identification of herb leaves is crucial for quality control, authentication, and
                    conservation of medicinal plants. The development of a herb leaf classification system that can
                    identify different herb species based on their leaf images can aid in the production of medicines,
                    as well as the identification and preservation of endangered plant species. Additionally, the
                    accurate labeling of herbs in natural environments can provide valuable data for ecological studies,
                    aiding in the conservation and management of natural habitats. Therefore, it is crucial to develop a
                    computer vision model that can accurately and efficiently identify different herb species in images,
                    as it has practical applications for the food industry, herb enthusiasts, medicinal purposes, and
                    environmental research.
                    <br><br>
            </div>
        </section>
        <hr class="m-0" />
        <!-- StateOfTheArt-->
        <section class="resume-section" id="StateOfTheArt">
            <div class="resume-section-content">
                <h2 class="mb-0">Current State Of The Art</h2>
                <p class="lead mb-5">In recent years, herb classification using leaf images has gained significant
                    attention due to its potential applications in the fields of medicine, agriculture, and food
                    industry. The ability to accurately identify different herb species can help in quality control of
                    herbal products, detection of adulteration, and conservation of rare and endangered plant species.
                    <br><br>
                    Most of the existing studies in this area have focused on the extraction of features from images
                    that represent a singular leaf from an herb and their classification using various machine learning
                    algorithms. Texture features, color histograms, and shape descriptors are some of the commonly used
                    features for herb classification[3]. However, with the recent advancements in deep
                    learning, several studies have started exploring the use of convolution neural networks (CNNs) for
                    herb recognition based on leaf images[1].
                    Leaf identification normally use images that taken in the laboratory with sophisticated equipment
                    and a white background. The accuracy of these models have been high.
                    <br><br>
                    Current research has shifted the focus from high-quality plant images to identifying leaves in
                    natural environments. Leaf segmentation in natural environments has different approaches and
                    accuracy levels. There have been many studies that aim to identify leaves based on images taken in
                    their natural environment[2]. These studies all focused on the identification of a
                    singular leaf taken in nature. The accuracy of the models was lower than the models discussed in the
                    prior paragraph that used images taken with sophisticated equipment and a white background, but the
                    models were still considered successful, with high accuracy.
                </p>
            </div>
        </section>
        <hr class="m-0" />
        <!-- Method-->
        <section class="resume-section" id="Method">
            <div class="resume-section-content">
                <h2 class="mb-0">Method</h2>
                <p class="lead mb-5">We explored the utilization of a convolutional neural network to assist with
                    quality/ripeness classification in contrast to
                    existing Feed-Forward Approaches[10]. In particularly, we chose a CNN model to evaluate how well a
                    purely visual system could work.
                    In order to train this model we tried to identify an existing image dataset with sufficient data
                    samples.
                    For insights and examples we explored a text
                    through the university library system that aligns with this project.[3] For feasibility, the
                    potential traits we
                    were focused on for identification were color and shape. </p>

                <h3 class="mb-0">Dataset</h3>
                <p class="lead mb-5">For this project, we were unable to find an already existing dataset. Therefore, we
                    will be creating our own dataset for the training & testing of model from Google Images. To create
                    the training & testing set we will pull 500-1000 images from Google Images for each of our four
                    herb types: parsley, thyme, chives, and oregano, and split the set into 90% and 10% to train &
                    test.
                    <br><br>
                    For the final test set we will be pulling 20-30 images of herb gardens. We will manually label these
                    images to test the prediction of our trained model in presence of multiple herbs in a single image.
                    Our main goal is to segment these herb garden images to segment into different herb-leaves region
                    and then predict their type in the image and label them.
                </p>
            </div>
        </section>
        <hr class="m-0" />
        <!-- Implementation-->
        <section class="resume-section" id="Implementation">
            <div class="resume-section-content">
                <h2 class="mb-0">Implementation Details</h2>
                <p class="lead mb-5">
                    As previously mentioned our approach to this problem was to implement a Convolutional Neural Network
                    image classifier trained on the data set
                    we obtained, labeled, and augmented. We decided on utilizing a CNN due to their utility in image
                    classification, which differs from
                    other work has been done utilizing Feed-Forward Neural Networks[10]. Beyond the introduction to
                    neural networks in lecture we leveraged the Python
                    library TensorFlow as our means of implementing the CNN classifier and got acquainted with the
                    framework via a tutorial[11]. The data set was split into
                    training, validation, and test subsets. The training and validation data sets were each used to
                    refine the CNN model which was then compared
                    against the held out testing data set. After evaluating the test accuracy the model's
                    hyper-parameters such as train-test split, number and
                    size of convolutional layers, and epoch count were varied and the resulting models test accuracy was
                    compared to the previous. After several iterations
                    we settled on a set of hyper-parameters that gave us satisfactory performance. In addition to
                    measuring the test accuracy, a sampling of misclassifications
                    was taken at each iteration and qualitatively judged to see if we would expect the images to be
                    reasonablly between multiple classes. The code
                    that was used for annotation and classification can be found in the resources section.

                </p>
            </div>
        </section>
        <hr class="m-0" />
        <!-- Results-->
        <section class="resume-section" id="Results">
            <div class="resume-section-content">
                <h2 class="mb-0">Results</h2>
                <p class="lead mb-5">
                    Overall, our latest trained model was able to achieve <strong>90.53%</strong> test accuracy on
                    images held out during training/validation.
                    Below are some selected examples of test images that were misclassified and the associated
                    correct/incorrect labels. Additionally, in Figure 1
                    we can see that the confusion matrix has little to no errors identified between the first and third
                    classes. This would suggest that most of
                    the classification errors may arise from border/transitory cases between the classes.
                </p>

                <div>Image 1.
                    <img src="./assets/img/misclass_1.png" alt="Misclassification 1">
                </div>

                <div>Image 2.
                    <img src="./assets/img/misclass_2.png" alt="Misclassification 2">
                </div>

                <div>Image 3.
                    <img src="./assets/img/misclass_3.png" alt="Misclassification 3">
                </div>

                <img src="./assets/img/conf_mat.png" alt="Confusion Matrix">
                <div>Figure 1. Confusion matrix between the three classes in the test data set.</div>


            </div>
        </section>
        <hr class="m-0" />
        <!-- Discussion-->
        <section class="resume-section" id="Discussion">
            <div class="resume-section-content">
                <h2 class="mb-0">Discussion</h2>
                <h3 class="mb-0">Challenges & Lessons</h3>
                <p class="lead mb-5">
                    Overall, we are satisfied with the performance we were able to achieve on image classification. Some
                    of the main take aways we had from this project
                    inluded the exploration into CNN functionality and implementation. One problem we encountered was
                    the limited data set size which lead to poor
                    convergence. To address this we augmented the data set utlizing image transformations (specifically
                    rotation and mirroring). Another issue
                    that was encountered was the cases were multiple classes could be identified within an image as
                    previously mentioned. With our fixed labeling
                    strategy of an image only belonging to one class we were unable to address this, but it might be an
                    oppurtunity for future work.
                </p>
                <p class="lead mb-5">
                    Beyond improvements in accuracy,
                    there a few ways we can consider building future work upon this project. Once a data set is currated
                    we can consider additional classification
                    goals such as being able to identify damaged, diseased, or overripe classes. We could extend this to
                    classification between different tomato
                    varieties. Beyond this, we could even consider applying these techniques to other forms of produce
                    such as strawberries or bananas. Additionally,
                    we could work on integrating non-visual data to be used in conjunction with the image data such as
                    the technologies identified in the Background
                    section.
                </p>
            </div>
        </section>
        <hr class="m-0" />
        <!-- Resources-->
        <section class="resume-section" id="Resources">
            <div class="resume-section-content">
                <h2 class="mb-0">Resources</h2>
                <ul class="lead mb-5">
                    <li>
                        <a href="https://drive.google.com/drive/folders/1xuNO52F8fC1eozGmujBlRK2z-yAQsf6O?usp=sharing">Annotation/Classification
                            Code</a>
                    </li>
                    <li>
                        <a
                            href="https://docs.google.com/presentation/d/1EqZvPVt7oMvXMxEGPtK4U5MUzi_V8G_ShqTcpjnI0OE/edit?usp=sharing">Presentation</a>
                    </li>
                </ul>
            </div>
        </section>
        <!-- References-->
        <section class="resume-section" id="References">
            <div class="resume-section-content">
                <h2 class="mb-0">References</h2>
                <ol class="lead mb-5">
                    <li>
                        Liu, Shupeng, Weiyang Chen, and Xiangjun Dong. 2018. “Automatic Classification of Chinese Herbal
                        Based on Deep Learning Method.” In 2018 14th International Conference on Natural Computation,
                        Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), 235–38.
                        https://doi.org/10.1109/FSKD.2018.8687165.

                    </li>
                    <li>
                        Mareta, Affix, Indah Soesanti, and Oyas Wahyunggoro. 2018. “Herbal Leaf Classification Using
                        Images in Natural Background.” In 2018 International Conference on Information and
                        Communications Technology (ICOIACT), 612–16. https://doi.org/10.1109/ICOIACT.2018.8350775.
                    </li>
                    <li>
                        Muneer, Amgad, and Suliman Mohamed Fati. 2020. “Efficient and Automated Herbs Classification
                        Approach Based on Shape and Texture Features Using Deep Learning.” IEEE Access 8: 196747–64.
                        https://doi.org/10.1109/ACCESS.2020.3034033.
                    </li>
                    <li>
                        <a href="https://www.tensorflow.org/tutorials/images/classification">TensorFlow Image
                            Classification Tutorial</a>
                    </li>
                </ol>
            </div>
        </section>
        <hr class="m-0" />
    </div>
    <!-- Bootstrap core JS-->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Core theme JS-->
    <script src="js/scripts.js"></script>
</body>

</html>